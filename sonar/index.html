<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Ultrasonic Tone Sonogram (19 kHz) — prototype</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 16px; }
    .row { display: flex; gap: 12px; flex-wrap: wrap; align-items: end; }
    .card { border: 1px solid #ddd; border-radius: 12px; padding: 12px; max-width: 1100px; }
    label { display: grid; gap: 4px; font-size: 12px; }
    input, select {
      padding: 6px 8px; border: 1px solid #ccc; border-radius: 8px; min-width: 140px;
      background: #fff;
    }
    button { padding: 8px 10px; border-radius: 10px; border: 1px solid #ccc; background: #fff; cursor: pointer; }
    button.primary { border-color: #888; font-weight: 600; }
    canvas { width: 100%; max-width: 1100px; height: auto; border: 1px solid #ddd; border-radius: 12px; }
    .muted { color: #666; font-size: 12px; }
    .warn { color: #8a3b00; font-size: 12px; }
    code { background: #f6f6f6; padding: 1px 6px; border-radius: 6px; }
    .kpi { display:flex; gap:16px; flex-wrap:wrap; margin-top:8px; }
    .kpi div { font-size:12px; color:#333; }
    .kpi b { font-size:12px; }
  </style>
</head>
<body>
  <h2>Ultrasonic "sonar" in browser (19 kHz, 1 channel, angle = orientation)</h2>
  <p class="muted">
    Prototype: Web Audio API → emit 19 kHz short bursts → record microphone → compute energy at 19 kHz over time (Goertzel) → draw sonogram.
  </p>

  <div class="card">
    <div class="row">
      <label>Frequency (Hz)
        <input id="freq" type="number" value="19000" min="16000" max="20000" step="10" />
      </label>

      <label>Burst duration (ms)
        <input id="burstMs" type="number" value="6" min="1" max="40" step="1" />
      </label>

      <label>Listen after (ms)
        <input id="listenMs" type="number" value="50" min="5" max="250" step="1" />
      </label>

      <label>Output channel
        <select id="channel">
          <option value="L">Left</option>
          <option value="R">Right</option>
        </select>
      </label>

      <label>Amplitude (0..1)
        <input id="amp" type="number" value="0.18" min="0.01" max="1" step="0.01" />
      </label>

      <label>Analysis window (samples)
        <input id="frame" type="number" value="512" min="128" max="4096" step="128" />
      </label>

      <label>Time step (samples)
        <input id="hop" type="number" value="128" min="32" max="2048" step="32" />
      </label>
    </div>

    <div class="row" style="margin-top:12px;">
      <button class="primary" id="btnStart">Start</button>
      <button id="btnStop" disabled>Stop</button>
      <button id="btnClear">Clear</button>
      <button id="btnPng">Export PNG</button>
      <button id="btnSensors">Enable sensors</button>
    </div>

    <p class="warn">
      ⚠️ 19–20 kHz is often filtered by speakers/microphones and "enhancements" (AEC/NS/AGC) on many devices. For testing, a PC + external audio interface often works better.
      Don't crank up the volume: "can't hear it" ≠ "safe".
    </p>

    <div class="muted" id="status">Status: idle</div>
    <div class="kpi">
      <div><b>sampleRate:</b> <span id="sr">—</span></div>
      <div><b>heading:</b> <span id="heading">—</span></div>
      <div><b>angle bucket:</b> <span id="bucket">—</span></div>
      <div><b>notes:</b> <span id="notes">—</span></div>
    </div>
  </div>

  <h3>Sonogram</h3>
  <canvas id="canvas" width="1100" height="520"></canvas>
  <p class="muted">
    X = angle (heading 0..360°, mapped across width), Y = "range" (time after emission). Brighter = more energy at 19 kHz in that delayed window.
  </p>

<script>
(() => {
  const $ = (id) => document.getElementById(id);
  const statusEl = $("status");
  const srEl = $("sr");
  const headingEl = $("heading");
  const bucketEl = $("bucket");
  const notesEl = $("notes");

  const canvas = $("canvas");
  const g = canvas.getContext("2d", { alpha: false });

  function setStatus(s) { statusEl.textContent = "Status: " + s; }
  function clamp(x,a,b){ return Math.max(a, Math.min(b,x)); }

  // --- Sonogram image buffer (grayscale)
  let img = null;

  function resetImage() {
    g.fillStyle = "#000";
    g.fillRect(0, 0, canvas.width, canvas.height);
    img = g.getImageData(0, 0, canvas.width, canvas.height);
    g.putImageData(img, 0, 0);
  }

  function drawColumnAtX(x, columnValues01) {
    const w = img.width, h = img.height;
    x = ((x % w) + w) % w;
    for (let y = 0; y < h; y++) {
      const v = clamp(columnValues01[y] ?? 0, 0, 1);
      const c = Math.floor(v * 255);
      const i = (y * w + x) * 4;
      img.data[i+0] = c;
      img.data[i+1] = c;
      img.data[i+2] = c;
      img.data[i+3] = 255;
    }
  }

  // --- Orientation / heading
  // headingDegrees: 0..360 (approx compass heading if absolute), otherwise just alpha-ish.
  let headingDegrees = 0;
  let hasHeading = false;

  function normalizeDeg(d) {
    d = d % 360;
    if (d < 0) d += 360;
    return d;
  }

  async function enableSensors() {
    notesEl.textContent = "";
    // iOS requires user gesture + permission for DeviceOrientationEvent
    try {
      if (typeof DeviceOrientationEvent !== "undefined" &&
          typeof DeviceOrientationEvent.requestPermission === "function") {
        const p = await DeviceOrientationEvent.requestPermission();
        if (p !== "granted") throw new Error("DeviceOrientation permission not granted");
      }
    } catch (e) {
      notesEl.textContent = "DeviceOrientation permission failed: " + (e?.message || e);
    }

    window.addEventListener("deviceorientation", (ev) => {
      // iOS Safari: webkitCompassHeading is the most useful
      if (typeof ev.webkitCompassHeading === "number") {
        headingDegrees = normalizeDeg(ev.webkitCompassHeading);
        hasHeading = true;
      } else if (ev.absolute === true && typeof ev.alpha === "number") {
        // absolute alpha: 0..360 (but on many devices absolute is unreliable)
        headingDegrees = normalizeDeg(ev.alpha);
        hasHeading = true;
      } else if (typeof ev.alpha === "number") {
        // fallback: relative yaw-ish
        headingDegrees = normalizeDeg(ev.alpha);
        hasHeading = true;
      }
      headingEl.textContent = hasHeading ? headingDegrees.toFixed(1) + "°" : "—";
    }, { passive: true });

    // If no events arrive, user will see heading unchanged.
    notesEl.textContent = "Sensors enabled (if supported). Rotate the device to change heading.";
  }

  // --- Audio
  let audioCtx = null;
  let micStream = null;
  let micSource = null;
  let micTap = null;
  let running = false;

  async function ensureAudio() {
    if (audioCtx) return;

    audioCtx = new (window.AudioContext || window.webkitAudioContext)({
      latencyHint: "interactive"
    });

    micStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: false,
        noiseSuppression: false,
        autoGainControl: false
      }
    });

    micSource = audioCtx.createMediaStreamSource(micStream);

    const useWorklet = !!audioCtx.audioWorklet;
    if (useWorklet) {
      const workletCode = `
        class TapProcessor extends AudioWorkletProcessor {
          process(inputs) {
            const input = inputs[0];
            if (input && input[0]) this.port.postMessage(input[0].slice(0));
            return true;
          }
        }
        registerProcessor('tap-processor', TapProcessor);
      `;
      const blob = new Blob([workletCode], { type: "application/javascript" });
      const url = URL.createObjectURL(blob);
      await audioCtx.audioWorklet.addModule(url);

      micTap = new AudioWorkletNode(audioCtx, "tap-processor");
      micSource.connect(micTap);
      // no destination connection needed for worklet tap
    } else {
      const bufSize = 2048;
      micTap = audioCtx.createScriptProcessor(bufSize, 1, 1);
      micSource.connect(micTap);
      micTap.connect(audioCtx.destination); // ScriptProcessor needs output connection
    }

    srEl.textContent = String(audioCtx.sampleRate);
  }

  // Generate a Hann-windowed tone burst
  function makeToneBurst(sr, freq, durationSec) {
    const N = Math.max(16, Math.floor(durationSec * sr));
    const x = new Float32Array(N);
    for (let n = 0; n < N; n++) {
      const t = n / sr;
      const w = 0.5 * (1 - Math.cos(2 * Math.PI * n / (N - 1))); // Hann
      x[n] = Math.sin(2 * Math.PI * freq * t) * w;
    }
    return x;
  }

  function playBurstOneChannel(burst, amp, channel /* 'L'|'R' */) {
    const sr = audioCtx.sampleRate;
    const N = burst.length;
    const buf = audioCtx.createBuffer(2, N, sr);
    const L = buf.getChannelData(0);
    const R = buf.getChannelData(1);

    if (channel === "L") {
      for (let i = 0; i < N; i++) { L[i] = burst[i] * amp; R[i] = 0; }
    } else {
      for (let i = 0; i < N; i++) { L[i] = 0; R[i] = burst[i] * amp; }
    }

    const src = audioCtx.createBufferSource();
    src.buffer = buf;
    src.connect(audioCtx.destination);
    src.start();
    return N / sr;
  }

  async function recordWindow(durationSec) {
    const sr = audioCtx.sampleRate;
    const need = Math.floor(durationSec * sr);
    const chunks = [];
    let got = 0;

    return new Promise((resolve) => {
      const onData = (data) => {
        chunks.push(data);
        got += data.length;
        if (got >= need) {
          const out = new Float32Array(got);
          let o = 0;
          for (const c of chunks) { out.set(c, o); o += c.length; }
          cleanup();
          resolve(out.subarray(0, need));
        }
      };

      const cleanup = () => {
        if (micTap instanceof AudioWorkletNode) micTap.port.onmessage = null;
        else micTap.onaudioprocess = null;
      };

      if (micTap instanceof AudioWorkletNode) {
        micTap.port.onmessage = (ev) => onData(ev.data);
      } else {
        micTap.onaudioprocess = (ev) => onData(new Float32Array(ev.inputBuffer.getChannelData(0)));
      }
    });
  }

  // --- Goertzel: power at a single target frequency for one frame
  function goertzelPower(frame, sr, freq) {
    const N = frame.length;
    const k = Math.round((N * freq) / sr);
    const w = (2 * Math.PI * k) / N;
    const cosw = Math.cos(w);
    const coeff = 2 * cosw;

    let s0 = 0, s1 = 0, s2 = 0;
    for (let n = 0; n < N; n++) {
      s0 = frame[n] + coeff * s1 - s2;
      s2 = s1;
      s1 = s0;
    }
    // power ~ s1^2 + s2^2 - coeff*s1*s2
    const power = s1*s1 + s2*s2 - coeff*s1*s2;
    return Math.max(0, power);
  }

  // Convert recorded tail to range bins (canvas height), measuring energy at freq over time
  function energyEnvelopeBins(recordedTail, sr, freq, frameSize, hopSize, bins) {
    const powers = [];
    for (let i = 0; i + frameSize <= recordedTail.length; i += hopSize) {
      const frame = recordedTail.subarray(i, i + frameSize);
      powers.push(goertzelPower(frame, sr, freq));
    }
    // Normalize powers
    let maxP = 1e-12;
    for (const p of powers) if (p > maxP) maxP = p;

    // Map powers to bins (downsample by max)
    const out = new Float32Array(bins);
    if (powers.length === 0) return out;

    const step = powers.length / bins;
    for (let b = 0; b < bins; b++) {
      const a = Math.floor(b * step);
      const z = Math.floor((b + 1) * step);
      let m = 0;
      for (let i = a; i < z; i++) m = Math.max(m, powers[i] / maxP);
      // gamma for contrast
      out[b] = Math.pow(clamp(m, 0, 1), 0.6);
    }
    return out;
  }

  function headingToX(deg) {
    const w = canvas.width;
    const x = Math.floor((normalizeDeg(deg) / 360) * (w - 1));
    return clamp(x, 0, w - 1);
  }

  async function scanLoop() {
    const freq = Number($("freq").value);
    const burstMs = Number($("burstMs").value);
    const listenMs = Number($("listenMs").value);
    const channel = String($("channel").value);
    const amp = Number($("amp").value);
    const frameSize = Number($("frame").value);
    const hopSize = Number($("hop").value);

    const sr = audioCtx.sampleRate;
    const burst = makeToneBurst(sr, freq, burstMs / 1000);

    running = true;
    setStatus("running");

    while (running) {
      // Pick angle from sensors; if not available, still draw sequentially by time using a moving x
      const deg = hasHeading ? headingDegrees : (performance.now() / 50) % 360;
      const x = headingToX(deg);
      bucketEl.textContent = String(x) + " / " + canvas.width;

      // Debug: log heading and X position to help diagnose drawing issues
      console.log(`[sonar] hasHeading=${hasHeading}, deg=${deg.toFixed(1)}, x=${x}`);

      // 1) play burst
      const burstSec = playBurstOneChannel(burst, amp, channel);

      // 2) record burst + listen
      const recSec = burstSec + (listenMs / 1000);
      const recorded = await recordWindow(recSec);

      // 3) take tail AFTER most of the emitted burst to reduce direct leakage
      const skip = Math.floor(burstSec * sr * 0.9);
      const tail = recorded.subarray(skip);

      // 4) energy envelope at freq -> bins
      const bins = energyEnvelopeBins(tail, sr, freq, frameSize, hopSize, canvas.height);

      // 5) draw column at heading position
      drawColumnAtX(x, bins);
      g.putImageData(img, 0, 0);

      // simple overlay label sometimes
      if (x % 80 === 0) {
        g.save();
        g.fillStyle = "rgba(255,255,255,0.85)";
        g.font = "12px system-ui";
        g.fillText(`${normalizeDeg(deg).toFixed(0)}°`, x + 6, 16);
        g.restore();
      }

      // yield
      await new Promise(r => setTimeout(r, 0));
    }

    setStatus("stopped");
  }

  // --- UI wiring
  $("btnSensors").onclick = async () => {
    await enableSensors();
  };

  $("btnStart").onclick = async () => {
    try {
      $("btnStart").disabled = true;
      $("btnStop").disabled = false;

      // Auto-enable sensors on Start (requires user gesture for iOS permission)
      await enableSensors();

      await ensureAudio();
      if (audioCtx.state !== "running") await audioCtx.resume();

      scanLoop();
    } catch (e) {
      console.error(e);
      setStatus("error: " + (e?.message || e));
      $("btnStart").disabled = false;
      $("btnStop").disabled = true;
    }
  };

  $("btnStop").onclick = () => {
    running = false;
    $("btnStop").disabled = true;
    $("btnStart").disabled = false;
  };

  $("btnClear").onclick = () => resetImage();

  $("btnPng").onclick = () => {
    const a = document.createElement("a");
    a.download = "sonogram_19k.png";
    a.href = canvas.toDataURL("image/png");
    a.click();
  };

  // init
  resetImage();
  setStatus("idle");
  headingEl.textContent = "—";
  bucketEl.textContent = "—";
})();
</script>
</body>
</html>
